---
description: Well-structured event data with thoughtful instrumentation enables precise
  routing effective troubleshooting and meaningful analysis in event-driven workflows
  while providing rich context through standardized fields timestamps and business-specific
  information.
id: a05fc315831dd94c474a6933b1101750
sidebar:
  order: 4
title: Best practices for instrumenting applications
---

Effective observability hinges on the quality of data your systems produce. For Tallyfy Manufactory to provide maximum value in managing and giving insight into your event-driven workflows, the events it ingests must be well-instrumented. This means thoughtfully deciding what information to include in your events.

## Why good instrumentation matters for Tallyfy Manufactory

The principle of "garbage in, garbage out" applies strongly here. The richness and clarity of the event data you send to Tallyfy Manufactory directly impacts:

*   **Manufactory's effectiveness:** Well-structured events with relevant data enable Manufactory to perform its core functions—like routing events to the correct [projects](/products/manufactory/projects/), triggering appropriate [actors](/products/manufactory/actors/), and managing event lifecycles—more accurately and efficiently.
*   **Your ability to analyze and troubleshoot:** Richly contextualized events are the raw material for meaningful analysis. Without good instrumentation, identifying the root cause of a problem in an event flow involving Manufactory becomes a difficult guessing game.
*   **The value of your observability practice:** The deeper your instrumentation, the more profound the insights you can derive about your system's behavior through Manufactory and associated observability tools.

## General principles of good instrumentation

Before diving into specifics for Tallyfy Manufactory, let's cover some universal principles for good instrumentation:

*   **Instrument for the data consumer:** Always think about who will be using this event data and what questions they will need to answer. This includes developers debugging issues, operations teams monitoring system health, and potentially product managers understanding feature usage through events processed by Manufactory.
*   **Context is king:** The more relevant context you can pack into an event, the more useful it becomes. Don't skimp on details that might seem minor now but could be crucial later during an investigation.
*   **Be consistent:** Use standardized field names (e.g., `user_id`, `trace_id`, `event_type`) and data formats where possible. This makes events easier to correlate and query across different sources and within Manufactory.
*   **Start early in the development lifecycle:** Don't treat instrumentation as an afterthought. Build it in as you develop new features or services that will interact with Tallyfy Manufactory.
*   **Iterate and refine:** Instrumentation is not a one-time setup. As your systems and your understanding of them evolve, you'll likely identify new pieces of information that would be valuable to include in your events sent to Manufactory.

## What data to include in events sent to Tallyfy Manufactory

When instrumenting an application to send an event to Tallyfy Manufactory, or when an actor within Manufactory generates an event, consider including the following types of data:

*   **Unique Identifiers:**
    *   `event_id`: A globally unique identifier for this specific event instance.
    *   `correlation_id`: An identifier that links this event to a broader business transaction or workflow instance (e.g., an `order_id` that ties together multiple events related to a single customer order).
    *   Identifiers for key business entities involved: `user_id`, `product_id`, `session_id`.
    *   If integrated with a Manufactory project: `manufactory_project_id`.
*   **Event Semantics:**
    *   `event_type` or `event_name`: A clear, human-readable string describing what happened (e.g., `InvoiceGenerated`, `ShipmentDelayed`, `PaymentAttemptFailed`).
    *   `event_source`: The name of the application, service, or component that originated this event.
    *   `event_version`: Useful if your event schemas change over time, allowing consumers like Manufactory to handle different versions appropriately.
*   **Timestamps:**
    *   The precise time the event occurred at its source.
    *   Tallyfy Manufactory will typically add its own timestamps for when it ingests or processes events, allowing for latency calculations.
*   **Payload:**
    *   The core data specific to this event type, structured in a clear and understandable way (e.g., for an `InvoiceGenerated` event, this might include `invoice_id`, `amount_due`, `due_date`).
    *   Avoid overly verbose data if it's not necessary for Manufactory's processing or for later analysis. Be mindful of payload size.
*   **Tracing Information (if implementing distributed tracing):**
    *   `trace_id`: The ID for the entire distributed trace this event is part of.
    *   `span_id`: The ID for this specific event's operation within the trace.
    *   `parent_span_id`: The ID of the operation that caused this event.
*   **Technical Context (optional, but can be very helpful for debugging):**
    *   `hostname` or `container_id` of the emitting service.
    *   `ip_address`.
    *   `environment` (e.g., `development`, `staging`, `production`).
    *   `application_version` or `build_id` of the emitting service.
*   **Business Context (can greatly enhance analysis):**
    *   `customer_segment` (e.g., `professional`, `smb`, `free_tier`).
    *   `region` (e.g., `us-east-1`, `eu-west-2`).
    *   Relevant `feature_flags_active` at the time of the event.

## Auto-instrumentation vs. manual instrumentation

There are generally two approaches to adding instrumentation:

*   **Auto-instrumentation:** Libraries or agents that automatically capture common events and metrics (e.g., incoming/outgoing HTTP requests, database queries) with minimal code changes.
    *   **Pros:** Quick to set up, provides broad baseline coverage.
    *   **Cons:** May not capture specific business logic or the nuanced context Tallyfy Manufactory needs. Events can be generic.
    *   **Relevance for Manufactory:** More useful for instrumenting the services *around* Manufactory (e.g., the service that calls a Manufactory API, or an actor that calls an external service). The actual events *sent to* Manufactory often require more specific detail than auto-instrumentation provides by default.
*   **Manual instrumentation:** Explicitly adding code to generate and send events with the exact data fields you define.
    *   **Pros:** Full control over event content, allowing you to tailor events perfectly for Manufactory's needs and your analytical requirements. Essential for capturing business-specific context.
    *   **Cons:** Requires more developer effort.

**Recommendation:** For events that are central to Tallyfy Manufactory's operation (i.e., events that trigger Manufactory projects or are processed by its actors), **manual or heavily customized auto-instrumentation is generally preferred.** This ensures the events contain the rich, specific, and contextual data Manufactory needs to function optimally and for you to gain meaningful observability.

## Instrumenting for event lifecycles managed by Manufactory

If Tallyfy Manufactory is orchestrating a multi-step business process through its projects and actors:

*   Ensure events clearly indicate the current **stage or status** of the overall process.
*   Include a common **correlation identifier** (e.g., `workflow_id`, `case_id`) in all events related to a single instance of that process.
*   Consider having actors within Manufactory emit their own events (with appropriate context) at the beginning and end of their significant processing steps, or when they make critical decisions. This provides visibility into Manufactory's internal workings.

## Example: Instrumenting an "Order Shipped" event for Manufactory

Imagine a `ShippingService` emits an `OrderShipped` event to be processed by Tallyfy Manufactory. Good instrumentation might include:

```json
{
  "event_id": "unique_event_guid_987",
  "event_type": "OrderShipped",
  "event_source": "ShippingService",
  "timestamp_occurred": "2023-10-27T16:45:10Z",
  "trace_id": "trace_for_order_processing_xyz",
  "order_id": "ORD-2023-10-552",
  "user_id": "usr_jane_doe",
  "shipment_id": "shp_fedex_123456789",
  "carrier_name": "FedEx",
  "tracking_number": "1234567890ABC",
  "shipping_cost": 25.99,
  "destination_zip_code": "90210",
  "items_shipped": [
    {"sku": "PROD_A", "quantity": 1},
    {"sku": "PROD_B", "quantity": 2}
  ]
}
```

When Tallyfy Manufactory ingests this event, it could trigger actors to: send a shipping confirmation email to the user, update the order status in an e-commerce platform, and notify the inventory system.
The rich data allows for precise actions and detailed observability.

## Avoiding common pitfalls

*   **Sending too little context:** Events become cryptic and hard to correlate or understand, diminishing Manufactory's (and your) ability to act on them.
*   **Inconsistent data formats or field names:** Makes querying and analysis difficult.
*   **Including sensitive Personally Identifiable Information (PII):** Ensure compliance with data privacy regulations. If sensitive data must be processed by Manufactory, understand its data handling policies and implement appropriate masking or tokenization upstream if necessary.
*   **Not versioning event schemas:** As your application evolves, so will your events. Versioning helps manage these changes gracefully, especially for consumers like Tallyfy Manufactory.

## How good instrumentation enhances the value of Tallyfy Manufactory

Thoughtful instrumentation is not just an operational task; it's an investment that directly boosts the value you get from Tallyfy Manufactory by:

*   Enabling more precise and intelligent event routing and filtering within your Manufactory [projects](/products/manufactory/projects/).
*   Allowing for more sophisticated and context-aware logic within your Manufactory [actors](/products/manufactory/actors/).
*   Providing superior visibility into the health, performance, and outcomes of your event-driven processes.
*   Making it significantly easier and faster to debug issues when they arise in workflows that touch Tallyfy Manufactory. 

import { CardGrid, LinkTitleCard } from "~/components";

## Related articles
<CardGrid>
<LinkTitleCard header="<b>Manufactory > Introduction to observability best practices</b>" href="/products/manufactory/best-practices/" > This comprehensive guide explains how observability practices enable deep understanding of event-driven systems through Tallyfy Manufactory by providing structured approaches to monitoring troubleshooting and analyzing system behavior using rich event data. </LinkTitleCard>
<LinkTitleCard header="<b>Best Practices > Understanding structured events</b>" href="/products/manufactory/best-practices/understanding-structured-events/" > Structured events in Tallyfy Manufactory use key-value pairs with specific fields and rich context to enable efficient routing processing analysis and monitoring of system activities through well-organized machine-parsable data formats. </LinkTitleCard>
<LinkTitleCard header="<b>Best Practices > Implementing distributed tracing for event workflows</b>" href="/products/manufactory/best-practices/implementing-distributed-tracing/" > Distributed tracing tracks single events as they cascade through multiple services in complex event-driven architectures by creating unique identifiers and hierarchical relationships that visualize the complete journey from initial trigger through processing stages like Tallyfy Manufactory ingestion routing and actor execution. </LinkTitleCard>
<LinkTitleCard header="<b>Best Practices > What is observability?</b>" href="/products/manufactory/best-practices/what-is-observability/" > Observability enables deep understanding of complex systems through detailed event data analysis to explore and debug both known and unknown issues without relying solely on predefined metrics. </LinkTitleCard>
</CardGrid>